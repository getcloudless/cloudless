{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cloudless Cloudless makes it easier to interact with cloud resources by doing most of the work that a human doesn't need to care about for you, and by being transparent about what it's doing. Homepage Documentation Github Installation This project depends on Python 3.6.0 or greater. To install, run: pip3 install cloudless Quick Start These examples show how to quickly create a simple service that is accessible on port 80 in Google Compute Engine and in Amazon Web Services. Run any command with --help for more usage. Google Compute Engine Credentials To set up the Google Compute Engine client, you must first create your Google Compute Engine account and navigate to https://console.cloud.google.com/iam-admin/serviceaccounts . There you can select your project and create a service account. Remember the service account email and create a key for this service account. Download and save this key on your local machine, remembering the path. You will also need the project ID (not the project name). Go to https://console.cloud.google.com/iam-admin/settings/project and select your project to find your project ID. When you think you have everything, run: cldls init --provider gce cldls network list This will set the \"default\" profile to use the \"gce\" backend. You can change the profile by passing --profile to cloudless or setting the CLOUDLESS_PROFILE environment variable. See Profiles for more information. Amazon Web Services Credentials To set up the Amazon Web Services client, follow the steps at https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html to configure the aws cli. Currently, cloudless only uses the \"default\" aws profile that is configured in this way. After you set up a default profile that works with the AWS cli, everything in cloudless should work. When you think you have this working, run: cldls init --provider aws cldls network list This will set the \"default\" profile to use the \"aws\" backend. You can change the profile by passing --profile to cloudless or setting the CLOUDLESS_PROFILE environment variable. See Profiles for more information. Simple Service The next steps are identical regardless of which cloud provider you're using. They do assume you have an image named \"cloudless-example-base-image-v0\" with Ubuntu 16.04 installed on it in your provider. See the Image Builder section for how to build an image like this using Cloudless. Once you have the prerequisites, you can create your service with: cldls network create mynet examples/network/blueprint.yml cldls service create mynet myservice examples/apache/blueprint.yml cldls paths allow_network_block mynet myservice 0.0.0.0/0 80 cldls service get mynet myservice # Navigate to the \"public_ip\" of each instance in a browser to see the service. Command Line Autocomplete Since this project uses click , autocomplete is built in. Just follow https://click.palletsprojects.com/en/5.x/bashcomplete/ if you use bash or https://github.com/click-contrib/click-completion for other shells. For example, for bash puth this in your .bashrc: eval \"$(_CLDLS_COMPLETE=source cldls)\" Profiles Both the API and the command line support using profiles that are created with cldls init . The order of priority for loading profiles is: Explicitly set via the profile argument to cloudless.Client in the python api, or via the --profile option to the cldls command line. Set in the CLOUDLESS_PROFILE environment variable. \"default\" Client Setup In Python API In the Python API, you must create a client object to connect to the cloud platform that you'll be working with. The client handles authentication with the cloud provider, so you must pass it the name of the provider and the authentication credentials. If you are trying this project for the first time, it's recommended that you use the \"mock-aws\" client. Google Compute Engine Client To use the Google Compute Engine client, you must create a service account and download the credentials locally. Because this provider is implemented using Apache Libcloud , you can refer to the Google Compute Engine Driver Setup documentation in that project for more details. When you have the credentials, you can do something like this, preferably in a dotfile you don't commit to version control. Note the credentials file is in JSON format: export CLOUDLESS_GCE_USER_ID=\"sverch-cloudless@cloudless-000000.iam.gserviceaccount.com\" export CLOUDLESS_GCE_CREDENTIALS_PATH=\"/home/sverch/.gce/credentials.json\" export CLOUDLESS_GCE_PROJECT_NAME=\"cloudless-000000\" Then, you can run these commands in a python shell to create a GCE client: import cloudless import os client = cloudless.Client(\"gce\", credentials={ \"user_id\": os.environ['CLOUDLESS_GCE_USER_ID'], \"key\": os.environ['CLOUDLESS_GCE_CREDENTIALS_PATH'], \"project\": os.environ['CLOUDLESS_GCE_PROJECT_NAME']}) If you want to avoid having to pass all this configuration explicitly to the client object, you can use a Cloudless Profile . Amazon Web Services Client Currently no credentials can be passed in as arguments for the AWS provider (they are ignored). However this provider is implemented with Boto , which looks in many other places for the credentials, so you can configure them in other ways. See the boto3 credential setup documentation for more details. Once you have set up your credentials, you can run the following to create an AWS client that uses the \"default\" aws profile (if you pass an empty credentials object, this cloudless profile will use whatever the AWS_PROFILE environment variable is set to, which might be confusing): import cloudless client = cloudless.Client(\"aws\", credentials={\"profile\": \"default\"}) If you want to avoid having to pass all this configuration explicitly to the client object, you can use a Cloudless Profile . Mock Amazon Web Services Client The Mock AWS client is for demonstration and testing. Since it is all running locally, you don't need any credentials. Simply run: import cloudless client = cloudless.Client(\"mock-aws\", credentials={}) Architecture There are only three objects in Cloudless: A Network, a Service, and a Path. This is an example that shows a Network dev , a public_load_balancer Service, an internal_service Service, a Path from the internet to public_load_balancer on port 443, and a Path from public_load_balancer to internal_service on port 80. See the visualization section for how to generate this graph. Network A Network is the top level container for everything else. To create a new network, run: dev_network = client.network.create(\"dev\") This will return the \"Network\" object that describes the network that was created. You can retrieve an existing network or list all existing networks by running: dev_network = client.network.get(\"dev\") all_networks = client.network.list() Finally, to destroy a network: client.network.destroy(dev_network) Create should use sane defaults, but if you need to do something special see docs/network-configuration.md . In ipython , you can run <object>? to get help on any object , for example client.network.create? . Service A Service a logical group of instances and whatever resources are needed to support them (subnetworks, firewalls, etc.). To create a Service, you must first define a configuration file called a \"blueprint\" that specifies how the service should be configured. This is an example of what a Service blueprint might look like: --- network: subnetwork_max_instance_count: 768 placement: availability_zones: 3 instance: public_ip: True memory: 4GB cpus: 1 gpu: false disks: - size: 8GB type: standard device_name: /dev/sda1 image: name: \"ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-*\" initialization: - path: \"haproxy-cloud-config.yml\" vars: PrivateIps: required: true The \"network\" section tells Cloudless to create subnetworks for this service big enough for 768 instances. The \"placement\" section tells Cloudless to ensure instances in this service are provisioned across three availaibility zones (which most cloud providers guarantee are meaningfully isolated from each other for resilience). The \"instance\" section describes the resource reqirements of each instance. Cloudless will automatically choose a instance type that meets these requirements. The \"image\" section represents the name of the image you want your instances to have. In this case, we are using an image name only found in AWS by default, so this example will only work there. See examples/apache for a blueprint that works cross cloud because it uses a custom image. The \"initialization\" section describes startup scripts that you want to run when the instance boots. You may also pass in variables, which will get passed to the given file as jinja2 template arguments. This is a good place to specify environment specific configuration, so your base image can stay the same across environments. Once you have the blueprint, the example below shows how you could use it. These examples create a group of private instances and then create some HAProxy instances in front of those instances to balance load. Note that many commands take dev_network as the first argument. That's the same network object returned by the network commands shown above. These assume you have created the base image in examples/base-image on the provider you are using. internal_service = client.service.create(dev_network, \"private\", blueprint=\"examples/nginx/blueprint.yml\") private_ips = [instance.private_ip for instance in client.service.get_instances(internal_service)] load_balancer_service = client.service.create(dev_network, \"public\", blueprint=\"examples/haproxy/blueprint.yml\", template_vars={\"PrivateIps\": private_ips}) internal_service = client.service.get(dev_network, \"public\") load_balancer_service client.service.get(dev_network, \"private\") client.service.list() client.service.destroy(internal_service) client.service.destroy(load_balancer_service) Path The Path is how you tell Cloudless that two services should be able to communicate. No blueprint is needed for this, but you need to have the service objects you created earlier. This example adds a path from the load balancer to the internal service on port 80 and makes the load balancer internet accessible on port 443: from cloudless.types.networking import CidrBlock internet = CidrBlock(\"0.0.0.0/0\") client.paths.add(load_balancer_service, internal_service, 80) client.paths.add(internet, load_balancer_service, 443) You can check whether things have access to other things or print out all paths with the following functions: client.paths.has_access(load_balancer_service, internal_service, 80) client.paths.internet_accessible(load_balancer_service, 443) client.paths.internet_accessible(internal_service, 443) client.paths.list() print(client.graph()) Visualization Get a summary in the form of a graphviz compatible dot file by running: client.graph() To generate the vizualizations, run: cd ui && env PROVIDER=<provider> bash graph.sh And open ui/graph.html in a browser. Note this won't work for the mock-aws provider since it will be running in a different process. Image Builder This project provides a cross cloud image builder that depends on the core cloudless APIs. this means that for the most part it is completely cloud independent, mod differences in the image that you start with (so it's completely independent if you're building your own custom image from scratch). For this example, we use the Ubuntu image provided by the cloud provider, so we have different blueprints for AWS and GCE (because the standard Ubuntu images they provide have different names). First, to deploy a service running a single instance: $ cldls --profile gce image-build deploy examples/base-image/gce_image_build_configuration.yml Next, to run the configure script. This is a shellscript that cloudless will pass the login credentials to as arguments, and where you can run your configuration as code scripts: $ cldls --profile gce image-build configure examples/base-image/gce_image_build_configuration.yml Next, to run the check script. This is another shellscript that cloudless will pass the login credentials to as arguments, and where you can run your validation to make sure the configuration step worked as expected: $ cldls --profile gce image-build check examples/base-image/gce_image_build_configuration.yml Finally, when you have your scripts working as you want them to, run a cleanup in preparation for a full build. Saving images without a full build is not supported to discourage modifications that are made on the machine and not recorded in scripts anywhere making it into the image: $ cldls --profile gce image-build cleanup examples/base-image/gce_image_build_configuration.yml Now, run the full build end to end, and you have your new image! $ cldls --profile gce image-build run examples/base-image/gce_image_build_configuration.yml We can list the image with: $ cldls --profile gce image list Image Name: cloudless-example-base-image-v0 Image Id: ami-0d7366265fcccbe46 Image Created At: 2018-09-20T16:51:03.000Z Get it by name with: $ cldls --profile gce image get cloudless-example-base-image-v0 Image Name: cloudless-example-base-image-v0 Image Id: ami-0d7366265fcccbe46 Image Created At: 2018-09-20T16:51:03.000Z And finally, delete the image. You might want to wait on this step because the Service Tester step below uses this image: $ cldls --profile gce image delete cloudless-example-base-image-v0 Deleted image: cloudless-example-base-image-v0 See examples/base-image for examples of how to create a cross cloud base image using this framework. Service Tester This project also provides a framework to help test that blueprint files work as expected. The framework will create, verify, and clean up the service under test. It also spins up all dependent services so you can test services \"in context\". It's sort of a hybrid between a unit test and an integration test. These examples assume the profile you have configured has an image that was built using the Image Builder step above. If you've followed those steps, these instructions are completely identical regardless of whether you're using AWS or GCE. First, to create the service: $ cldls service-test deploy examples/apache/service_test_configuration.yml Creation complete! To log in, run: ssh -i examples/apache/id_rsa_test cloudless_service_test@35.237.12.140 $ ssh -i examples/apache/id_rsa_test cloudless_service_test@35.237.12.140 ... ... Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. cloudless@test-network-jmeiwknbsg-test-service-hswonxmeda-0:~$ This will create a temporary network to sandbox the test. Now, to verify that the service is behaving as expected: $ cldls service-test check examples/apache/service_test_configuration.yml INFO:cloudless.providers.gce:Discovering subnetwork test-network-jmeiwknbsg, test-service-hswonxmeda INFO:cloudless.util:Attempt number: 1 INFO:cloudless.util:Check successful! Check complete! To log in, run: ssh -i examples/apache/id_rsa_test cloudless@35.237.12.140 Finally, to clean up everything: $ cldls service-test cleanup examples/apache/service_test_configuration.yml If you want to run all the previous steps all together, you can run: $ cldls service-test run examples/apache/service_test_configuration.yml See examples for examples of how to set up a blueprint to be testable with this framework. Testing To run the local tests run: pipenv install --dev tox To run tests against GCE and AWS, run: tox -e gce tox -e aws These will use the gce-cloudless-test and aws-cloudless-test cloudless profiles respectively. See Profiles for more information.","title":"Home"},{"location":"#cloudless","text":"Cloudless makes it easier to interact with cloud resources by doing most of the work that a human doesn't need to care about for you, and by being transparent about what it's doing. Homepage Documentation Github","title":"Cloudless"},{"location":"#installation","text":"This project depends on Python 3.6.0 or greater. To install, run: pip3 install cloudless","title":"Installation"},{"location":"#quick-start","text":"These examples show how to quickly create a simple service that is accessible on port 80 in Google Compute Engine and in Amazon Web Services. Run any command with --help for more usage.","title":"Quick Start"},{"location":"#google-compute-engine-credentials","text":"To set up the Google Compute Engine client, you must first create your Google Compute Engine account and navigate to https://console.cloud.google.com/iam-admin/serviceaccounts . There you can select your project and create a service account. Remember the service account email and create a key for this service account. Download and save this key on your local machine, remembering the path. You will also need the project ID (not the project name). Go to https://console.cloud.google.com/iam-admin/settings/project and select your project to find your project ID. When you think you have everything, run: cldls init --provider gce cldls network list This will set the \"default\" profile to use the \"gce\" backend. You can change the profile by passing --profile to cloudless or setting the CLOUDLESS_PROFILE environment variable. See Profiles for more information.","title":"Google Compute Engine Credentials"},{"location":"#amazon-web-services-credentials","text":"To set up the Amazon Web Services client, follow the steps at https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html to configure the aws cli. Currently, cloudless only uses the \"default\" aws profile that is configured in this way. After you set up a default profile that works with the AWS cli, everything in cloudless should work. When you think you have this working, run: cldls init --provider aws cldls network list This will set the \"default\" profile to use the \"aws\" backend. You can change the profile by passing --profile to cloudless or setting the CLOUDLESS_PROFILE environment variable. See Profiles for more information.","title":"Amazon Web Services Credentials"},{"location":"#simple-service","text":"The next steps are identical regardless of which cloud provider you're using. They do assume you have an image named \"cloudless-example-base-image-v0\" with Ubuntu 16.04 installed on it in your provider. See the Image Builder section for how to build an image like this using Cloudless. Once you have the prerequisites, you can create your service with: cldls network create mynet examples/network/blueprint.yml cldls service create mynet myservice examples/apache/blueprint.yml cldls paths allow_network_block mynet myservice 0.0.0.0/0 80 cldls service get mynet myservice # Navigate to the \"public_ip\" of each instance in a browser to see the service.","title":"Simple Service"},{"location":"#command-line-autocomplete","text":"Since this project uses click , autocomplete is built in. Just follow https://click.palletsprojects.com/en/5.x/bashcomplete/ if you use bash or https://github.com/click-contrib/click-completion for other shells. For example, for bash puth this in your .bashrc: eval \"$(_CLDLS_COMPLETE=source cldls)\"","title":"Command Line Autocomplete"},{"location":"#profiles","text":"Both the API and the command line support using profiles that are created with cldls init . The order of priority for loading profiles is: Explicitly set via the profile argument to cloudless.Client in the python api, or via the --profile option to the cldls command line. Set in the CLOUDLESS_PROFILE environment variable. \"default\"","title":"Profiles"},{"location":"#client-setup-in-python-api","text":"In the Python API, you must create a client object to connect to the cloud platform that you'll be working with. The client handles authentication with the cloud provider, so you must pass it the name of the provider and the authentication credentials. If you are trying this project for the first time, it's recommended that you use the \"mock-aws\" client.","title":"Client Setup In Python API"},{"location":"#google-compute-engine-client","text":"To use the Google Compute Engine client, you must create a service account and download the credentials locally. Because this provider is implemented using Apache Libcloud , you can refer to the Google Compute Engine Driver Setup documentation in that project for more details. When you have the credentials, you can do something like this, preferably in a dotfile you don't commit to version control. Note the credentials file is in JSON format: export CLOUDLESS_GCE_USER_ID=\"sverch-cloudless@cloudless-000000.iam.gserviceaccount.com\" export CLOUDLESS_GCE_CREDENTIALS_PATH=\"/home/sverch/.gce/credentials.json\" export CLOUDLESS_GCE_PROJECT_NAME=\"cloudless-000000\" Then, you can run these commands in a python shell to create a GCE client: import cloudless import os client = cloudless.Client(\"gce\", credentials={ \"user_id\": os.environ['CLOUDLESS_GCE_USER_ID'], \"key\": os.environ['CLOUDLESS_GCE_CREDENTIALS_PATH'], \"project\": os.environ['CLOUDLESS_GCE_PROJECT_NAME']}) If you want to avoid having to pass all this configuration explicitly to the client object, you can use a Cloudless Profile .","title":"Google Compute Engine Client"},{"location":"#amazon-web-services-client","text":"Currently no credentials can be passed in as arguments for the AWS provider (they are ignored). However this provider is implemented with Boto , which looks in many other places for the credentials, so you can configure them in other ways. See the boto3 credential setup documentation for more details. Once you have set up your credentials, you can run the following to create an AWS client that uses the \"default\" aws profile (if you pass an empty credentials object, this cloudless profile will use whatever the AWS_PROFILE environment variable is set to, which might be confusing): import cloudless client = cloudless.Client(\"aws\", credentials={\"profile\": \"default\"}) If you want to avoid having to pass all this configuration explicitly to the client object, you can use a Cloudless Profile .","title":"Amazon Web Services Client"},{"location":"#mock-amazon-web-services-client","text":"The Mock AWS client is for demonstration and testing. Since it is all running locally, you don't need any credentials. Simply run: import cloudless client = cloudless.Client(\"mock-aws\", credentials={})","title":"Mock Amazon Web Services Client"},{"location":"#architecture","text":"There are only three objects in Cloudless: A Network, a Service, and a Path. This is an example that shows a Network dev , a public_load_balancer Service, an internal_service Service, a Path from the internet to public_load_balancer on port 443, and a Path from public_load_balancer to internal_service on port 80. See the visualization section for how to generate this graph.","title":"Architecture"},{"location":"#network","text":"A Network is the top level container for everything else. To create a new network, run: dev_network = client.network.create(\"dev\") This will return the \"Network\" object that describes the network that was created. You can retrieve an existing network or list all existing networks by running: dev_network = client.network.get(\"dev\") all_networks = client.network.list() Finally, to destroy a network: client.network.destroy(dev_network) Create should use sane defaults, but if you need to do something special see docs/network-configuration.md . In ipython , you can run <object>? to get help on any object , for example client.network.create? .","title":"Network"},{"location":"#service","text":"A Service a logical group of instances and whatever resources are needed to support them (subnetworks, firewalls, etc.). To create a Service, you must first define a configuration file called a \"blueprint\" that specifies how the service should be configured. This is an example of what a Service blueprint might look like: --- network: subnetwork_max_instance_count: 768 placement: availability_zones: 3 instance: public_ip: True memory: 4GB cpus: 1 gpu: false disks: - size: 8GB type: standard device_name: /dev/sda1 image: name: \"ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-*\" initialization: - path: \"haproxy-cloud-config.yml\" vars: PrivateIps: required: true The \"network\" section tells Cloudless to create subnetworks for this service big enough for 768 instances. The \"placement\" section tells Cloudless to ensure instances in this service are provisioned across three availaibility zones (which most cloud providers guarantee are meaningfully isolated from each other for resilience). The \"instance\" section describes the resource reqirements of each instance. Cloudless will automatically choose a instance type that meets these requirements. The \"image\" section represents the name of the image you want your instances to have. In this case, we are using an image name only found in AWS by default, so this example will only work there. See examples/apache for a blueprint that works cross cloud because it uses a custom image. The \"initialization\" section describes startup scripts that you want to run when the instance boots. You may also pass in variables, which will get passed to the given file as jinja2 template arguments. This is a good place to specify environment specific configuration, so your base image can stay the same across environments. Once you have the blueprint, the example below shows how you could use it. These examples create a group of private instances and then create some HAProxy instances in front of those instances to balance load. Note that many commands take dev_network as the first argument. That's the same network object returned by the network commands shown above. These assume you have created the base image in examples/base-image on the provider you are using. internal_service = client.service.create(dev_network, \"private\", blueprint=\"examples/nginx/blueprint.yml\") private_ips = [instance.private_ip for instance in client.service.get_instances(internal_service)] load_balancer_service = client.service.create(dev_network, \"public\", blueprint=\"examples/haproxy/blueprint.yml\", template_vars={\"PrivateIps\": private_ips}) internal_service = client.service.get(dev_network, \"public\") load_balancer_service client.service.get(dev_network, \"private\") client.service.list() client.service.destroy(internal_service) client.service.destroy(load_balancer_service)","title":"Service"},{"location":"#path","text":"The Path is how you tell Cloudless that two services should be able to communicate. No blueprint is needed for this, but you need to have the service objects you created earlier. This example adds a path from the load balancer to the internal service on port 80 and makes the load balancer internet accessible on port 443: from cloudless.types.networking import CidrBlock internet = CidrBlock(\"0.0.0.0/0\") client.paths.add(load_balancer_service, internal_service, 80) client.paths.add(internet, load_balancer_service, 443) You can check whether things have access to other things or print out all paths with the following functions: client.paths.has_access(load_balancer_service, internal_service, 80) client.paths.internet_accessible(load_balancer_service, 443) client.paths.internet_accessible(internal_service, 443) client.paths.list() print(client.graph())","title":"Path"},{"location":"#visualization","text":"Get a summary in the form of a graphviz compatible dot file by running: client.graph() To generate the vizualizations, run: cd ui && env PROVIDER=<provider> bash graph.sh And open ui/graph.html in a browser. Note this won't work for the mock-aws provider since it will be running in a different process.","title":"Visualization"},{"location":"#image-builder","text":"This project provides a cross cloud image builder that depends on the core cloudless APIs. this means that for the most part it is completely cloud independent, mod differences in the image that you start with (so it's completely independent if you're building your own custom image from scratch). For this example, we use the Ubuntu image provided by the cloud provider, so we have different blueprints for AWS and GCE (because the standard Ubuntu images they provide have different names). First, to deploy a service running a single instance: $ cldls --profile gce image-build deploy examples/base-image/gce_image_build_configuration.yml Next, to run the configure script. This is a shellscript that cloudless will pass the login credentials to as arguments, and where you can run your configuration as code scripts: $ cldls --profile gce image-build configure examples/base-image/gce_image_build_configuration.yml Next, to run the check script. This is another shellscript that cloudless will pass the login credentials to as arguments, and where you can run your validation to make sure the configuration step worked as expected: $ cldls --profile gce image-build check examples/base-image/gce_image_build_configuration.yml Finally, when you have your scripts working as you want them to, run a cleanup in preparation for a full build. Saving images without a full build is not supported to discourage modifications that are made on the machine and not recorded in scripts anywhere making it into the image: $ cldls --profile gce image-build cleanup examples/base-image/gce_image_build_configuration.yml Now, run the full build end to end, and you have your new image! $ cldls --profile gce image-build run examples/base-image/gce_image_build_configuration.yml We can list the image with: $ cldls --profile gce image list Image Name: cloudless-example-base-image-v0 Image Id: ami-0d7366265fcccbe46 Image Created At: 2018-09-20T16:51:03.000Z Get it by name with: $ cldls --profile gce image get cloudless-example-base-image-v0 Image Name: cloudless-example-base-image-v0 Image Id: ami-0d7366265fcccbe46 Image Created At: 2018-09-20T16:51:03.000Z And finally, delete the image. You might want to wait on this step because the Service Tester step below uses this image: $ cldls --profile gce image delete cloudless-example-base-image-v0 Deleted image: cloudless-example-base-image-v0 See examples/base-image for examples of how to create a cross cloud base image using this framework.","title":"Image Builder"},{"location":"#service-tester","text":"This project also provides a framework to help test that blueprint files work as expected. The framework will create, verify, and clean up the service under test. It also spins up all dependent services so you can test services \"in context\". It's sort of a hybrid between a unit test and an integration test. These examples assume the profile you have configured has an image that was built using the Image Builder step above. If you've followed those steps, these instructions are completely identical regardless of whether you're using AWS or GCE. First, to create the service: $ cldls service-test deploy examples/apache/service_test_configuration.yml Creation complete! To log in, run: ssh -i examples/apache/id_rsa_test cloudless_service_test@35.237.12.140 $ ssh -i examples/apache/id_rsa_test cloudless_service_test@35.237.12.140 ... ... Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. cloudless@test-network-jmeiwknbsg-test-service-hswonxmeda-0:~$ This will create a temporary network to sandbox the test. Now, to verify that the service is behaving as expected: $ cldls service-test check examples/apache/service_test_configuration.yml INFO:cloudless.providers.gce:Discovering subnetwork test-network-jmeiwknbsg, test-service-hswonxmeda INFO:cloudless.util:Attempt number: 1 INFO:cloudless.util:Check successful! Check complete! To log in, run: ssh -i examples/apache/id_rsa_test cloudless@35.237.12.140 Finally, to clean up everything: $ cldls service-test cleanup examples/apache/service_test_configuration.yml If you want to run all the previous steps all together, you can run: $ cldls service-test run examples/apache/service_test_configuration.yml See examples for examples of how to set up a blueprint to be testable with this framework.","title":"Service Tester"},{"location":"#testing","text":"To run the local tests run: pipenv install --dev tox To run tests against GCE and AWS, run: tox -e gce tox -e aws These will use the gce-cloudless-test and aws-cloudless-test cloudless profiles respectively. See Profiles for more information.","title":"Testing"},{"location":"client/","text":"cloudless Cloudless is a python library to provide a basic set of easy to use primitive operations that can work with many different cloud providers. These primitives are: Create a \"Network\" (also known as VPC, Network, Environment). e.g. \"dev\". Create a \"Service\" within that network. e.g. \"apache-public\". Easily control network connections and firewalls using \"Paths\". The goal is to provide an intuitive abstraction that is powerful enough to build on, so that building other layers on top is easy and anything built on it is automatically cross cloud. The main entry point to this module is through the cloudless.Client object, and all calls that interact with a backing cloud provider go through this object. Client Client(self, profile=None, provider=None, credentials=None) Top Level Cloudless Client. This is the object through which all calls to the backing service provider are made. Most functionality is stored in the subclasses that are attached to this client. Currently they are cloudless.NetworkClient , cloudless.ServiceClient , and cloudless.PathsClient . See the documentation on those sub-components for more usage details. To use: import cloudless client = cloudless.Client(provider, credentials) client.network? client.service? client.paths? Where \"provider\" is the backing service provider, and \"credentials\" is a hash containing whatever credentials are required by the chosen provider. See the supported providers list for details. graph Client.graph(self) Return a DOT formatted graph string containing all resources on the current provider. This string can be passed to a program like graphviz to generate a graph visualization. NetworkClient NetworkClient(self, provider, credentials) Cloudless Network Client. This is the object through which all network related calls are made. The objects returned by these commands are of type cloudless.types.common.Network . Usage: import cloudless client = cloudless.Client(provider, credentials) client.network.create(\"network\", blueprint=\"tests/blueprints/network.yml\") client.network.get(\"network\") client.network.list() client.network.destroy(client.network.get(\"network\")) The above commands will create and destroy a network named \"network\". create NetworkClient.create(self, name, blueprint=None) Create new network named \"name\" with blueprint file at \"blueprint\". Example: client.network.create(\"mynetwork\", \"network-blueprint.yml\") get NetworkClient.get(self, name) Get a network named \"name\" and return some data about it. Example: client.network.get(\"mynetwork\") destroy NetworkClient.destroy(self, network) Destroy the given network. Example: client.network.destroy(client.network.get(\"mynetwork\")) list NetworkClient.list(self) List all networks. Example: client.network.list() ServiceClient ServiceClient(self, provider, credentials) Cloudless Service Client. This is the object through which all service related calls are made. The objects returned by these commands are of type cloudless.types.common.Service which contain objects of type cloudless.types.common.Subnetwork , which themselves contain lists of cloudless.types.common.Instance . This is because the service is the logical grouping, but behind the scenes they are groups of instances deployed in private subnetworks. Usage: import cloudless client = cloudless.Client(provider, credentials) network = client.network.create(\"network\", blueprint=\"tests/blueprints/network.yml\") client.service.create(network, \"public\", blueprint=\"tests/blueprints/service.yml\") myservice = client.service.get(mynetwork, \"public\") client.service.list() client.service.destroy(myservice) The above commands will create and destroy a service named \"public\" in the network \"network\". create ServiceClient.create(self, network, service_name, blueprint, template_vars=None, count=None) Create a service in \"network\" named \"service_name\" with blueprint file at \"blueprint\". \"template_vars\" are passed to the initialization scripts as jinja2 variables. Example: example_network = client.network.create(\"example\") example_service = client.service.create(network=example_network, name=\"example_service\", blueprint=\"example-blueprint.yml\") get ServiceClient.get(self, network, service_name) Get a service in \"network\" named \"service_name\". Example: example_service = client.service.get(network=client.network.get(\"example\"), name=\"example_service\") get_instances ServiceClient.get_instances(self, service) Helper to return the list of instances given a service object. Example: example_service = client.service.get(network=client.network.get(\"example\"), name=\"example_service\") instances = client.service.get_instances(example_service) destroy ServiceClient.destroy(self, service) Destroy a service described by the \"service\" object. Example: example_service = client.service.get(network=client.network.get(\"example\"), name=\"example_service\") client.service.destroy(example_service) list ServiceClient.list(self) List all services. Example: client.service.list() node_types ServiceClient.node_types(self) Get mapping of node types to the resources. Example: client.service.node_types() PathsClient PathsClient(self, provider, credentials) Cloudless Paths Client. This is the object through which all path related calls are made. The objects returned by these commands are of type cloudless.types.common.Path which contain objects of type cloudless.types.common.Service and cloudless.types.networking.CidrBlock depending on whether the path is internally or externally facing. Usage: import cloudless client = cloudless.Client(provider, credentials) internal_service = client.service.get(network, \"internal_service\") load_balancer = client.service.get(network, \"load_balancer\") internet = cloudless.types.networking.CidrBlock(\"0.0.0.0/0\") client.paths.add(load_balancer, internal_service, 80) client.paths.add(internet, load_balancer, 443) client.paths.list() client.graph() The above commands will result in the public internet having access to \"load_balancer\" on port 443 and \"load_balancer\" having access to \"internal_service\" on port 80. add PathsClient.add(self, source, destination, port) Make the service or cidr block described by \"destination\" accessible from the service or cidr block described by \"source\" on the given port. Either \"source\" or \"destination\" must be a service object. Example: service1 = client.service.get(network=client.network.get(\"example\"), name=\"service1\") service2 = client.service.get(network=client.network.get(\"example\"), name=\"service2\") internet = cloudless.types.networking.CidrBlock(\"0.0.0.0/0\") client.paths.add(service1, service2, 443) client.paths.add(internet, service1, 80) remove PathsClient.remove(self, source, destination, port) Ensure the service or cidr block described by \"destination\" is not accessible from the service or cidr block described by \"source\" on the given port. Either \"source\" or \"destination\" must be a service object. Example: service1 = client.service.get(network=client.network.get(\"example\"), name=\"service1\") service2 = client.service.get(network=client.network.get(\"example\"), name=\"service2\") internet = cloudless.types.networking.CidrBlock(\"0.0.0.0/0\") client.paths.remove(service1, service2, 443) client.paths.remove(internet, service1, 80) list PathsClient.list(self) List all paths and return a dictionary structure representing a graph. Example: client.paths.list() internet_accessible PathsClient.internet_accessible(self, service, port) Returns true if the service described by \"service\" is internet accessible on the given port. Example: service1 = client.service.get(network=client.network.get(\"example\"), name=\"service1\") client.paths.internet_accessible(service1, 443) has_access PathsClient.has_access(self, source, destination, port) Returns true if the service or cidr block described by \"destination\" is accessible from the service or cidr block described by \"source\" on the given port. Either \"source\" or \"destination\" must be a service object. Example: service1 = client.service.get(network=client.network.get(\"example\"), name=\"service1\") service2 = client.service.get(network=client.network.get(\"example\"), name=\"service2\") internet = cloudless.types.networking.CidrBlock(\"0.0.0.0/0\") client.paths.has_access(service1, service2, 443) client.paths.has_access(internet, service1, 80)","title":"Core API"},{"location":"client/#cloudless","text":"Cloudless is a python library to provide a basic set of easy to use primitive operations that can work with many different cloud providers. These primitives are: Create a \"Network\" (also known as VPC, Network, Environment). e.g. \"dev\". Create a \"Service\" within that network. e.g. \"apache-public\". Easily control network connections and firewalls using \"Paths\". The goal is to provide an intuitive abstraction that is powerful enough to build on, so that building other layers on top is easy and anything built on it is automatically cross cloud. The main entry point to this module is through the cloudless.Client object, and all calls that interact with a backing cloud provider go through this object.","title":"cloudless"},{"location":"client/#client","text":"Client(self, profile=None, provider=None, credentials=None) Top Level Cloudless Client. This is the object through which all calls to the backing service provider are made. Most functionality is stored in the subclasses that are attached to this client. Currently they are cloudless.NetworkClient , cloudless.ServiceClient , and cloudless.PathsClient . See the documentation on those sub-components for more usage details. To use: import cloudless client = cloudless.Client(provider, credentials) client.network? client.service? client.paths? Where \"provider\" is the backing service provider, and \"credentials\" is a hash containing whatever credentials are required by the chosen provider. See the supported providers list for details.","title":"Client"},{"location":"client/#graph","text":"Client.graph(self) Return a DOT formatted graph string containing all resources on the current provider. This string can be passed to a program like graphviz to generate a graph visualization.","title":"graph"},{"location":"client/#networkclient","text":"NetworkClient(self, provider, credentials) Cloudless Network Client. This is the object through which all network related calls are made. The objects returned by these commands are of type cloudless.types.common.Network . Usage: import cloudless client = cloudless.Client(provider, credentials) client.network.create(\"network\", blueprint=\"tests/blueprints/network.yml\") client.network.get(\"network\") client.network.list() client.network.destroy(client.network.get(\"network\")) The above commands will create and destroy a network named \"network\".","title":"NetworkClient"},{"location":"client/#create","text":"NetworkClient.create(self, name, blueprint=None) Create new network named \"name\" with blueprint file at \"blueprint\". Example: client.network.create(\"mynetwork\", \"network-blueprint.yml\")","title":"create"},{"location":"client/#get","text":"NetworkClient.get(self, name) Get a network named \"name\" and return some data about it. Example: client.network.get(\"mynetwork\")","title":"get"},{"location":"client/#destroy","text":"NetworkClient.destroy(self, network) Destroy the given network. Example: client.network.destroy(client.network.get(\"mynetwork\"))","title":"destroy"},{"location":"client/#list","text":"NetworkClient.list(self) List all networks. Example: client.network.list()","title":"list"},{"location":"client/#serviceclient","text":"ServiceClient(self, provider, credentials) Cloudless Service Client. This is the object through which all service related calls are made. The objects returned by these commands are of type cloudless.types.common.Service which contain objects of type cloudless.types.common.Subnetwork , which themselves contain lists of cloudless.types.common.Instance . This is because the service is the logical grouping, but behind the scenes they are groups of instances deployed in private subnetworks. Usage: import cloudless client = cloudless.Client(provider, credentials) network = client.network.create(\"network\", blueprint=\"tests/blueprints/network.yml\") client.service.create(network, \"public\", blueprint=\"tests/blueprints/service.yml\") myservice = client.service.get(mynetwork, \"public\") client.service.list() client.service.destroy(myservice) The above commands will create and destroy a service named \"public\" in the network \"network\".","title":"ServiceClient"},{"location":"client/#create_1","text":"ServiceClient.create(self, network, service_name, blueprint, template_vars=None, count=None) Create a service in \"network\" named \"service_name\" with blueprint file at \"blueprint\". \"template_vars\" are passed to the initialization scripts as jinja2 variables. Example: example_network = client.network.create(\"example\") example_service = client.service.create(network=example_network, name=\"example_service\", blueprint=\"example-blueprint.yml\")","title":"create"},{"location":"client/#get_1","text":"ServiceClient.get(self, network, service_name) Get a service in \"network\" named \"service_name\". Example: example_service = client.service.get(network=client.network.get(\"example\"), name=\"example_service\")","title":"get"},{"location":"client/#get_instances","text":"ServiceClient.get_instances(self, service) Helper to return the list of instances given a service object. Example: example_service = client.service.get(network=client.network.get(\"example\"), name=\"example_service\") instances = client.service.get_instances(example_service)","title":"get_instances"},{"location":"client/#destroy_1","text":"ServiceClient.destroy(self, service) Destroy a service described by the \"service\" object. Example: example_service = client.service.get(network=client.network.get(\"example\"), name=\"example_service\") client.service.destroy(example_service)","title":"destroy"},{"location":"client/#list_1","text":"ServiceClient.list(self) List all services. Example: client.service.list()","title":"list"},{"location":"client/#node_types","text":"ServiceClient.node_types(self) Get mapping of node types to the resources. Example: client.service.node_types()","title":"node_types"},{"location":"client/#pathsclient","text":"PathsClient(self, provider, credentials) Cloudless Paths Client. This is the object through which all path related calls are made. The objects returned by these commands are of type cloudless.types.common.Path which contain objects of type cloudless.types.common.Service and cloudless.types.networking.CidrBlock depending on whether the path is internally or externally facing. Usage: import cloudless client = cloudless.Client(provider, credentials) internal_service = client.service.get(network, \"internal_service\") load_balancer = client.service.get(network, \"load_balancer\") internet = cloudless.types.networking.CidrBlock(\"0.0.0.0/0\") client.paths.add(load_balancer, internal_service, 80) client.paths.add(internet, load_balancer, 443) client.paths.list() client.graph() The above commands will result in the public internet having access to \"load_balancer\" on port 443 and \"load_balancer\" having access to \"internal_service\" on port 80.","title":"PathsClient"},{"location":"client/#add","text":"PathsClient.add(self, source, destination, port) Make the service or cidr block described by \"destination\" accessible from the service or cidr block described by \"source\" on the given port. Either \"source\" or \"destination\" must be a service object. Example: service1 = client.service.get(network=client.network.get(\"example\"), name=\"service1\") service2 = client.service.get(network=client.network.get(\"example\"), name=\"service2\") internet = cloudless.types.networking.CidrBlock(\"0.0.0.0/0\") client.paths.add(service1, service2, 443) client.paths.add(internet, service1, 80)","title":"add"},{"location":"client/#remove","text":"PathsClient.remove(self, source, destination, port) Ensure the service or cidr block described by \"destination\" is not accessible from the service or cidr block described by \"source\" on the given port. Either \"source\" or \"destination\" must be a service object. Example: service1 = client.service.get(network=client.network.get(\"example\"), name=\"service1\") service2 = client.service.get(network=client.network.get(\"example\"), name=\"service2\") internet = cloudless.types.networking.CidrBlock(\"0.0.0.0/0\") client.paths.remove(service1, service2, 443) client.paths.remove(internet, service1, 80)","title":"remove"},{"location":"client/#list_2","text":"PathsClient.list(self) List all paths and return a dictionary structure representing a graph. Example: client.paths.list()","title":"list"},{"location":"client/#internet_accessible","text":"PathsClient.internet_accessible(self, service, port) Returns true if the service described by \"service\" is internet accessible on the given port. Example: service1 = client.service.get(network=client.network.get(\"example\"), name=\"service1\") client.paths.internet_accessible(service1, 443)","title":"internet_accessible"},{"location":"client/#has_access","text":"PathsClient.has_access(self, source, destination, port) Returns true if the service or cidr block described by \"destination\" is accessible from the service or cidr block described by \"source\" on the given port. Either \"source\" or \"destination\" must be a service object. Example: service1 = client.service.get(network=client.network.get(\"example\"), name=\"service1\") service2 = client.service.get(network=client.network.get(\"example\"), name=\"service2\") internet = cloudless.types.networking.CidrBlock(\"0.0.0.0/0\") client.paths.has_access(service1, service2, 443) client.paths.has_access(internet, service1, 80)","title":"has_access"},{"location":"objects/","text":"Network Network(self, name:str, network_id:str, cidr_block:str=None, region:str=None) -> None Simple container to hold network information. Service Service(self, network:cloudless.types.common.Network, name:str, subnetworks:list) -> None Simple container to hold service information. Subnetwork Subnetwork(self, subnetwork_id:str, name:str, cidr_block:str, region:str, availability_zone:str, instances:list) -> None Simple container to hold subnetwork information. Instance Instance(self, instance_id:str, public_ip:str, private_ip:str, state:str, availability_zone:str) -> None Simple container to hold instance information. Path Path(self, network:cloudless.types.common.Network, source, destination, protocol:str, port:int) -> None Simple container to hold path information.","title":"Object Types"},{"location":"objects/#network","text":"Network(self, name:str, network_id:str, cidr_block:str=None, region:str=None) -> None Simple container to hold network information.","title":"Network"},{"location":"objects/#service","text":"Service(self, network:cloudless.types.common.Network, name:str, subnetworks:list) -> None Simple container to hold service information.","title":"Service"},{"location":"objects/#subnetwork","text":"Subnetwork(self, subnetwork_id:str, name:str, cidr_block:str, region:str, availability_zone:str, instances:list) -> None Simple container to hold subnetwork information.","title":"Subnetwork"},{"location":"objects/#instance","text":"Instance(self, instance_id:str, public_ip:str, private_ip:str, state:str, availability_zone:str) -> None Simple container to hold instance information.","title":"Instance"},{"location":"objects/#path","text":"Path(self, network:cloudless.types.common.Network, source, destination, protocol:str, port:int) -> None Simple container to hold path information.","title":"Path"},{"location":"providers/","text":"cloudless.providers These providers are what actually provide the resources that cloudless manages. Changing the provider should change where things are provisioned, but not change anything about the usage of the core API. The currently supported providers are \"gce\" for Google Compute Engine, \"aws\" for Amazon Web Services, and \"mock-aws\" for Mock Amazon Web Services. Mock AWS is useful for trying cloudless locally without provisioning any resources. Example usage: import cloudless mock_aws = cloudless.client(provider=\"mock-aws\", credentials={}) mock_aws.network.create(name=\"example\", blueprint=\"blueprint.yml\") mock_aws.network.list() This creates a network named example using the \"mock-aws\" client. This doesn't actually create the network, but cloudless will think it exists for the duration of the session so the mock_aws.network.list() command will show it. cloudless.providers.aws_mock The Mock AWS provider will provision resources using a library called moto , which is a mock client for Amazon Web Services. This means that no resources will get provisioned, but cloudless will see what you create for the duration of your session. You should not use this directly, but instead pass in the string \"mock-aws\" as the \"provider\" in the top level cloudless.Client object. cloudless.providers.gce The GCE Provider will provision resources using Google Compute Engine. You should not use this directly, but instead pass in the string \"gce\" as the \"provider\" in the top level cloudless.Client object. cloudless.providers.aws The AWS provider will provision resources using Amazon Web Services. You should not use this directly, but instead pass in the string \"aws\" as the \"provider\" in the top level cloudless.Client object.","title":"Providers"},{"location":"providers/#cloudlessproviders","text":"These providers are what actually provide the resources that cloudless manages. Changing the provider should change where things are provisioned, but not change anything about the usage of the core API. The currently supported providers are \"gce\" for Google Compute Engine, \"aws\" for Amazon Web Services, and \"mock-aws\" for Mock Amazon Web Services. Mock AWS is useful for trying cloudless locally without provisioning any resources. Example usage: import cloudless mock_aws = cloudless.client(provider=\"mock-aws\", credentials={}) mock_aws.network.create(name=\"example\", blueprint=\"blueprint.yml\") mock_aws.network.list() This creates a network named example using the \"mock-aws\" client. This doesn't actually create the network, but cloudless will think it exists for the duration of the session so the mock_aws.network.list() command will show it.","title":"cloudless.providers"},{"location":"providers/#cloudlessprovidersaws_mock","text":"The Mock AWS provider will provision resources using a library called moto , which is a mock client for Amazon Web Services. This means that no resources will get provisioned, but cloudless will see what you create for the duration of your session. You should not use this directly, but instead pass in the string \"mock-aws\" as the \"provider\" in the top level cloudless.Client object.","title":"cloudless.providers.aws_mock"},{"location":"providers/#cloudlessprovidersgce","text":"The GCE Provider will provision resources using Google Compute Engine. You should not use this directly, but instead pass in the string \"gce\" as the \"provider\" in the top level cloudless.Client object.","title":"cloudless.providers.gce"},{"location":"providers/#cloudlessprovidersaws","text":"The AWS provider will provision resources using Amazon Web Services. You should not use this directly, but instead pass in the string \"aws\" as the \"provider\" in the top level cloudless.Client object.","title":"cloudless.providers.aws"},{"location":"docs/network-configuration/","text":"Network Configuration A network can be configured by passing a \"blueprint\" argument to the create command. A Blueprint file for a network with the defaults set might look like: --- network: legacy_network_size_bits: 16 allowed_private_cidr: \"10.0.0.0/8\" The legacy_network_size_bits option only matters for the AWS provider, since GCE lets you creates subnets directly without a top level network, but AWS does not. That option tells AWS to create a top level network (VPC) of size 16, which will mean that the network has 2^16 unique IP addresses in it. Note that everything is currently still using IPv4. The allowed_private_cidr is useful if you might peer networks and don't want the private ranges to overlap. For AWS you must set this on the network creation call, but since GCE doesn't allocate any networks until subnetworks are created you must set this block in the service blueprint for GCE to honor your allowed ranges.","title":"Network Configuration"},{"location":"docs/network-configuration/#network-configuration","text":"A network can be configured by passing a \"blueprint\" argument to the create command. A Blueprint file for a network with the defaults set might look like: --- network: legacy_network_size_bits: 16 allowed_private_cidr: \"10.0.0.0/8\" The legacy_network_size_bits option only matters for the AWS provider, since GCE lets you creates subnets directly without a top level network, but AWS does not. That option tells AWS to create a top level network (VPC) of size 16, which will mean that the network has 2^16 unique IP addresses in it. Note that everything is currently still using IPv4. The allowed_private_cidr is useful if you might peer networks and don't want the private ranges to overlap. For AWS you must set this on the network creation call, but since GCE doesn't allocate any networks until subnetworks are created you must set this block in the service blueprint for GCE to honor your allowed ranges.","title":"Network Configuration"}]}